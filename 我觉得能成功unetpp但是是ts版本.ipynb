{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "我觉得能成功unetpp但是是ts版本.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2CLYkohe6CFn",
        "R9nZ6YEw6EjL",
        "IOoM4Hxy1KxK",
        "LeXxiAPrBBfE"
      ],
      "mount_file_id": "1hyvFOTknQIxm3RrkSsVzykuHlPLIiqAp",
      "authorship_tag": "ABX9TyPMmNNeTLsUPkotgBQpvSWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CallMeL/Medical-Image-Segmentation/blob/main/%E6%88%91%E8%A7%89%E5%BE%97%E8%83%BD%E6%88%90%E5%8A%9Funetpp%E4%BD%86%E6%98%AF%E6%98%AFts%E7%89%88%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[参考reference](https://github.com/sauravmishra1710/UNet-Plus-Plus---Brain-Tumor-Segmentation)\n",
        "\n",
        "下一步https://github.com/CallMeL/unet-pytorch"
      ],
      "metadata": {
        "id": "RwV4D3x_LV0b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qb-WTstn2lrl",
        "outputId": "777c832f-6873-4d3d-854e-5ea3773b0263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UNet-Plus-Plus---Brain-Tumor-Segmentation'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 130 (delta 56), reused 88 (delta 25), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (130/130), 35.95 MiB | 13.90 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sauravmishra1710/UNet-Plus-Plus---Brain-Tumor-Segmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/UNet-Plus-Plus---Brain-Tumor-Segmentation"
      ],
      "metadata": {
        "id": "lyFEf3D_5tXl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensorflow"
      ],
      "metadata": {
        "id": "r3ZswNeZ4fbb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageDataGen"
      ],
      "metadata": {
        "id": "2CLYkohe6CFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gc\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class ImageDataGen(tf.keras.utils.Sequence):\n",
        "    \n",
        "    \"\"\"\n",
        "    The custom data generator class generates and feeds data to\n",
        "    the model dynamically in batches during the training phase.\n",
        "    \n",
        "    This generator generates batched of data for the dataset available @\n",
        "    Find the nuclei in divergent images to advance medical discovery -\n",
        "    https://www.kaggle.com/c/data-science-bowl-2018\n",
        "    \n",
        "    **\n",
        "    tf.keras.utils.Sequence is the root class for \n",
        "    Custom Data Generators.\n",
        "    **\n",
        "    \n",
        "    Args:\n",
        "        image_ids: the ids of the image.\n",
        "        img_path: the full path of the image directory.\n",
        "        mask_path: the full path of the mask directory.\n",
        "        batch_size: no. of images to be included in a batch feed. Default is set to 32.\n",
        "        image_size: size of the image. Default is set to 512 as per the data available.\n",
        "        \n",
        "    Ref: https://dzlab.github.io/dltips/en/keras/data-generator/\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, image_ids, img_path, mask_path, batch_size = 32, image_size = 512, shuffle = True):\n",
        "        \n",
        "        self.ids = image_ids\n",
        "        self.img_path = img_path\n",
        "        self.mask_path = mask_path\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __load__(self, item):\n",
        "        \n",
        "        \"\"\"\n",
        "        loads the specified image.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        full_image_path = os.path.join(self.img_path, item)\n",
        "        full_mask_path = os.path.join(self.mask_path, item)\n",
        "        \n",
        "        # load the images\n",
        "        image = cv2.imread(full_image_path, 0)\n",
        "        image = cv2.resize(image, (self.image_size, self.image_size))\n",
        "        \n",
        "        # load the masks\n",
        "        mask = cv2.imread(full_mask_path, 0)\n",
        "        mask = cv2.resize(mask, (self.image_size, self.image_size))\n",
        "        \n",
        "        # normalize the mask and the image. \n",
        "        image = image/255.0\n",
        "        mask = mask/255.0\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        \"\"\"\n",
        "        Returns a single batch of data.\n",
        "        \n",
        "        Args:\n",
        "            index: the batch index.\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        # edge case scenario where there are still some items left\n",
        "        # after segregatings the images into batches of size batch_size.\n",
        "        # the items left out will form one batch at the end.\n",
        "        if(index + 1) * self.batch_size > len(self.ids):\n",
        "            self.batch_size = len(self.ids) - index * self.batch_size\n",
        "        \n",
        "        # group the items into a batch.\n",
        "        batch = self.ids[index * self.batch_size : (index + 1) * self.batch_size]\n",
        "        \n",
        "        image = []\n",
        "        mask  = []\n",
        "        \n",
        "        # load the items in the current batch\n",
        "        for item in batch:\n",
        "            img, msk = self.__load__(item)\n",
        "            image.append(img)\n",
        "            mask.append(msk)\n",
        "        \n",
        "        image = np.array(image)\n",
        "        mask  = np.array(mask)\n",
        "        \n",
        "        return image, mask\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        optional method to run some logic at the end of each epoch: e.g. reshuffling\n",
        "        \n",
        "        \"\"\"\n",
        "        \n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.ids)\n",
        "            \n",
        "        gc.collect()\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        Returns the number of batches\n",
        "        \"\"\"\n",
        "        return int(np.ceil(len(self.ids)/float(self.batch_size)))\n",
        "    "
      ],
      "metadata": {
        "id": "n6HyjtdI599A"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### UNetPlusPlus"
      ],
      "metadata": {
        "id": "R9nZ6YEw6EjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, concatenate, Conv2DTranspose\n",
        "from tensorflow.keras.layers import MaxPooling2D, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "class UNetPlusPlus():\n",
        "    \n",
        "    \"\"\" \n",
        "    Unet++ Model design.\n",
        "    \n",
        "    This module consumes the Unet utilities framework moule and designs the Unet network.\n",
        "    It consists of a contracting path and an expansive path. Both these paths are joined \n",
        "    by a bottleneck block.\n",
        "    \n",
        "    The different blocks involved in the design of the network can be referenced @ \n",
        "    U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
        "    \n",
        "    Reference:\n",
        "        [1] UNet++: A Nested U-Net Architecture for Medical Image Segmentation.\n",
        "            https://arxiv.org/abs/1807.10165\n",
        "            \n",
        "        [2] https://paperswithcode.com/paper/unet-a-nested-u-net-architecture-for-medical\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, input_shape = (512, 512, 1), filters = [32, 64, 128, 256, 512], nb_classes = 1, deep_supervision = False):\n",
        "        \n",
        "        \"\"\"\n",
        "        Initialize the Unet framework and the model parameters - input_shape, \n",
        "        filters and padding type. \n",
        "        \n",
        "        Args:\n",
        "            input_shape (tuple): A shape tuple (integers), not including the batch size.\n",
        "                                 Default value is (512, 512, 1).\n",
        "                                 \n",
        "            filters (array of integers: a collection of filters denoting the number of components to be used at each blocks along the \n",
        "                        contracting and expansive paths. The original paper implementation for number of filters along the \n",
        "                        contracting and expansive paths are [32, 64, 128, 256, 512]. (as per paper: k = 32 × 2^i).\n",
        "                        \n",
        "            nb_classes (Integer): the dimensionality (no. of filters) of the output space .\n",
        "                        (i.e. the number of output filters in the convolution).\n",
        "\n",
        "            deep_supervision (boolean): A flag that toggles between the 2 different training modes -\n",
        "                                        1) the ACCURATE mode - where the outputs from all segmentation \n",
        "                                           branches are averaged., \n",
        "                                        2) the FAST mode - wherein the final segmentation map is selected from \n",
        "                                           only one of the segmentation branches.\n",
        "                                        Default vaue - False\n",
        "            \n",
        "        **Remarks: The default values are as per the implementation in the original paper @ https://arxiv.org/pdf/1505.04597\n",
        "         \n",
        "        \"\"\"\n",
        "\n",
        "        self.__input_shape = input_shape\n",
        "        self.__filters = filters\n",
        "        self.__nb_classes = nb_classes\n",
        "        self.__deep_supervision = deep_supervision\n",
        "        self.__smooth = 1. # Used to prevent the denominator from 0 when computing the DICE coefficient.\n",
        "    \n",
        "    def BuildNetwork(self):\n",
        "\n",
        "        \"\"\"\n",
        "        Creates the UNet++ Netwrork for biomedical image segmentation.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "            \n",
        "        Returns:\n",
        "            model: the neural network model representing the UNet++ model architechture.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        input_img = Input(shape = self.__input_shape, name = 'InputLayer')\n",
        "\n",
        "        conv00 = self.__InsertConvolutionBlock(input_img, block_level = '00', filters = self.__filters[0])\n",
        "        pool0 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool0')(conv00)\n",
        "\n",
        "        conv10 = self.__InsertConvolutionBlock(pool0, block_level = '10', filters = self.__filters[1])\n",
        "        pool1 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool1')(conv10)\n",
        "\n",
        "        up01 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding='same', name='upsample01')(conv10)\n",
        "        conv01 = concatenate([up01, conv00], name='concat01')\n",
        "        conv01 = self.__InsertConvolutionBlock(conv01, block_level = '01', filters = self.__filters[0])\n",
        "\n",
        "        conv20 = self.__InsertConvolutionBlock(pool1, block_level = '20', filters = self.__filters[2])\n",
        "        pool2 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool2')(conv20)\n",
        "\n",
        "        up11 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample11')(conv20)\n",
        "        conv11 = concatenate([up11, conv10], name = 'concat11')\n",
        "        conv11 = self.__InsertSkipPathway(conv11, block_level = '11', filters = self.__filters[1])\n",
        "\n",
        "        up02 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding='same', name='upsample02')(conv11)\n",
        "        conv02 = concatenate([up02, conv00, conv01], name = 'concat02')\n",
        "        conv02 = self.__InsertConvolutionBlock(conv02, block_level = '02', filters = self.__filters[0])\n",
        "\n",
        "        conv30 = self.__InsertConvolutionBlock(pool2, block_level = '30', filters = self.__filters[3])\n",
        "        pool3 = MaxPooling2D(pool_size = 2, strides = 2, name = 'pool3')(conv30)\n",
        "\n",
        "        up21 = Conv2DTranspose(filters = self.__filters[2], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample21')(conv30)\n",
        "        conv21 = concatenate([up21, conv20], name='concat21')\n",
        "\n",
        "        conv21 = self.__InsertConvolutionBlock(conv21, block_level='21', filters = self.__filters[2])\n",
        "\n",
        "        up12 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding='same', name = 'upsample12')(conv21)\n",
        "        conv12 = concatenate([up12, conv10, conv11], name = 'concat12')\n",
        "        conv12 = self.__InsertSkipPathway(conv12, block_level = '12', filters = self.__filters[1])\n",
        "\n",
        "        up03 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample03')(conv12)\n",
        "        conv03 = concatenate([up03, conv00, conv01, conv02], name = 'concat03')\n",
        "        conv03 = self.__InsertConvolutionBlock(conv03, block_level = '03', filters = self.__filters[0])\n",
        "\n",
        "        conv40 = self.__InsertConvolutionBlock(pool3, block_level = '40', filters = self.__filters[4])\n",
        "\n",
        "        up31 = Conv2DTranspose(filters = self.__filters[3], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample31')(conv40)\n",
        "        conv31 = concatenate([up31, conv30], name = 'concat31')\n",
        "        conv31 = self.__InsertSkipPathway(conv31, block_level = '31', filters=self.__filters[3])\n",
        "\n",
        "        up22 = Conv2DTranspose(filters = self.__filters[2], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample22')(conv31)\n",
        "        conv22 = concatenate([up22, conv20, conv21], name = 'concat22')\n",
        "        conv22 = self.__InsertSkipPathway(conv22, block_level = '22', filters = self.__filters[2])\n",
        "\n",
        "        up13 = Conv2DTranspose(filters = self.__filters[1], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample13')(conv22)\n",
        "        conv13 = concatenate([up13, conv10, conv11, conv12], name='concat13')\n",
        "        conv13 = self.__InsertSkipPathway(conv13, block_level = '13', filters = self.__filters[1])\n",
        "\n",
        "        up04 = Conv2DTranspose(filters = self.__filters[0], kernel_size = 2, strides = 2, padding = 'same', name = 'upsample04')(conv13)\n",
        "        conv04 = concatenate([up04, conv00, conv01, conv02, conv03], name = 'concat04')\n",
        "        conv04 = self.__InsertConvolutionBlock(conv04, block_level = '04', filters = self.__filters[0])\n",
        "\n",
        "        nested_op_1 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
        "                                  padding = 'same', name = 'op1')(conv01)\n",
        "\n",
        "        nested_op_2 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
        "                                  padding = 'same', name = 'op2')(conv02)\n",
        "\n",
        "        nested_op_3 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
        "                                  padding= 'same', name = 'op3')(conv03)\n",
        "\n",
        "        nested_op_4 = Conv2D(filters = self.__nb_classes, kernel_size = 1, activation = tf.nn.sigmoid, \n",
        "                                  padding = 'same', name = 'op4')(conv04)\n",
        "\n",
        "        if self.__deep_supervision:\n",
        "            output = [nested_op_1, nested_op_2, nested_op_3, nested_op_4]\n",
        "        else:\n",
        "            output = [nested_op_4]\n",
        "\n",
        "        model = Model(inputs = input_img, outputs = output, name = \"UNetPP\")\n",
        "\n",
        "        return model\n",
        "\n",
        "    def __InsertSkipPathway(self, input_tensor, block_level, filters, kernel_size = 3):\n",
        "\n",
        "        \"\"\"\n",
        "        Inserts a convolution block along the skip pathways.\n",
        "\n",
        "        Args:\n",
        "            input_tensor: The input that would go into the convolutional block.\n",
        "            block_level: the level of the current block.\n",
        "            filters: the dimensionality (no. of filters) of the output space \n",
        "                        (i.e. the number of output filters in the convolution).\n",
        "            kernel_size: the size of the convolving window. Default value is 3.\n",
        "                         All convolutional layers along a skip pathway (X(i, j) )\n",
        "                         use k kernels of size 3×3.\n",
        "\n",
        "        Returns:\n",
        "            x: The 2D convolution output.\n",
        "\n",
        "        \"\"\"\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
        "                   padding = 'same', name = 'conv' + block_level + '_1')(input_tensor)\n",
        "\n",
        "        x = Dropout(rate = 0.5, name = 'X' + block_level + '_')(x)\n",
        "\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
        "                   padding = 'same', name = 'conv' + block_level + '_2')(x)\n",
        "\n",
        "        x = Dropout(rate = 0.5, name = 'X' + block_level)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def __InsertConvolutionBlock(self, input_tensor, block_level, filters, kernel_size = 3):\n",
        "\n",
        "        \"\"\"\n",
        "        Inserts a convolution block along the contracting \n",
        "        and expanding paths of the network.\n",
        "\n",
        "        Args:\n",
        "            input_tensor: The input that would go into the convolutional block.\n",
        "            block_level: the level of the current block.\n",
        "            filters: the dimensionality (no. of filters) of the output space \n",
        "                        (i.e. the number of output filters in the convolution).\n",
        "            kernel_size: the size of the convolving window. Default value is 3.            \n",
        "\n",
        "        Returns:\n",
        "            x: The 2D convolution output.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
        "                   padding = 'same', name = 'conv' + block_level + '_1')(input_tensor)\n",
        "\n",
        "        x = Dropout(rate = 0.5, name = 'X' + block_level + '_')(x)\n",
        "\n",
        "        x = Conv2D(filters = filters, kernel_size = kernel_size, activation = tf.nn.relu, \n",
        "                   padding = 'same', name = 'conv' + block_level + '_2')(x)\n",
        "\n",
        "        x = Dropout(rate = 0.5, name = 'X' + block_level)(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "    # WARNING:tensorflow:AutoGraph could not transform <bound method UNetPlusPlus.__dice_coef_loss of \n",
        "    # <UNetPP.UNetPlusPlus object at 0x000001A33B0D8198>> and will run it as-is.\n",
        "    # Cause: mangled names are not yet supported. To silence this warning, decorate the function with \n",
        "    # @tf.autograph.experimental.do_not_convert\n",
        "    @tf.autograph.experimental.do_not_convert\n",
        "    def __dice_coef(self, y_true, y_pred):\n",
        "        \n",
        "        \"\"\"\n",
        "        computes the dice loss. loss function for image segmentation \n",
        "        tasks is based on the Dice coefficient, which is essentially \n",
        "        a measure of overlap between two samples. This measure ranges \n",
        "        from 0 to 1 where a Dice coefficient of 1 denotes perfect and \n",
        "        complete overlap.\n",
        "        \n",
        "        Args:\n",
        "            y_true: the true value of the image mask.\n",
        "            y_pred: the predicted value of the image mask.\n",
        "        \n",
        "        Returns:\n",
        "            dice_val: the dice loss value\n",
        "            \n",
        "        Ref:\n",
        "            https://www.programmersought.com/article/11533881518/\n",
        "            \n",
        "        \"\"\"\n",
        "        \n",
        "        y_true_f = K.flatten(y_true) # Extend y_true to one dimension.\n",
        "        y_pred_f = K.flatten(y_pred)\n",
        "        intersection = K.sum(y_true_f * y_pred_f)\n",
        "        return (2. * intersection + self.__smooth) / (K.sum(y_true_f * y_true_f) + K.sum(y_pred_f * y_pred_f) + self.__smooth)\n",
        "    \n",
        "    @tf.autograph.experimental.do_not_convert\n",
        "    def __dice_coef_loss(self, y_true, y_pred):\n",
        "        \n",
        "        \"\"\"\n",
        "        computes the dice loss. loss function for image segmentation \n",
        "        tasks is based on the Dice coefficient, which is essentially \n",
        "        a measure of overlap between two samples. This measure ranges \n",
        "        from 0 to 1 where a Dice coefficient of 1 denotes perfect and \n",
        "        complete overlap.\n",
        "        \n",
        "        Args:\n",
        "            y_true: the true value of the image mask.\n",
        "            y_pred: the predicted value of the image mask.\n",
        "        \n",
        "        Returns:\n",
        "            dice_val: the dice loss value\n",
        "            \n",
        "        Ref:\n",
        "            https://www.programmersought.com/article/11533881518/\n",
        "            \n",
        "        \"\"\"\n",
        "        \n",
        "        return 1. - self.__dice_coef(y_true, y_pred)\n",
        "    \n",
        "    \n",
        "    @tf.autograph.experimental.do_not_convert\n",
        "    def __iou_loss_core(self, y_true, y_pred):\n",
        "        \n",
        "        \"\"\"\n",
        "        computes the intersection over union metric. \n",
        "        Intersection over Union is an evaluation metric \n",
        "        used to measure the accuracy of an object/mask detected. \n",
        "        \n",
        "        Args:\n",
        "            y_true: the true value of the image mask.\n",
        "            y_pred: the predicted value of the image mask.\n",
        "            smooth: \n",
        "        \n",
        "        Returns:\n",
        "            iou: the iou coefficient.\n",
        "            \n",
        "        \"\"\"\n",
        "        intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "        union = K.sum(y_true,-1) + K.sum(y_pred,-1) - intersection\n",
        "        iou = (intersection + self.__smooth) / ( union + self.__smooth)\n",
        "        \n",
        "        return iou\n",
        "    \n",
        "    def CompileAndSummarizeModel(self, model, optimizer = \"adam\", loss = \"binary_crossentropy\"):\n",
        "\n",
        "        \"\"\"\n",
        "        Compiles and displays the model summary of the Unet++ model.\n",
        "\n",
        "        Args:\n",
        "            model: The keras instance of the Unet++ model.\n",
        "            optimizer: model optimizer. Default is the adam optimizer.\n",
        "            loss: the loss function. Default is the binary cross entropy loss.\n",
        "\n",
        "        Return:\n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "        model.compile(optimizer = optimizer, \n",
        "                      loss = self.__dice_coef_loss, \n",
        "                      metrics = ['acc', self.__iou_loss_core])\n",
        "        \n",
        "        model.summary()\n",
        "\n",
        "    def plotModel(self, model, to_file = 'unetpp.png', show_shapes = True, dpi = 96):\n",
        "\n",
        "        \"\"\"\n",
        "        Saves the Unet++ model plot/figure to a file.\n",
        "\n",
        "        Args:\n",
        "            model: The keras instance of the Unet++ model.\n",
        "            to_file: the file name to save the model. Default name - 'unet.png'.\n",
        "            show_shapes: whether to display shape information. Default = True.\n",
        "            dpi: dots per inch. Default value is 96.\n",
        "\n",
        "        Return:\n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        tf.keras.utils.plot_model(model, to_file = to_file, show_shapes = show_shapes, dpi = dpi)"
      ],
      "metadata": {
        "id": "Jth3gr7N6FAV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ImageDataExtractor\n",
        "注意：这个下面有个self.download的部分被注释掉了，第一次跑还是加上，总之就是先下载zip，然后把mat解压，然后调用readmat和saveimg变成image和mask\n",
        "\n",
        "attention: the `self.download` part in the next cell has been commented, if you run it for the first time, do remember to uncomment them, or simply copy the original code in the `/content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/ImageDataExtractor.py` file( important: change the '\\*.mat' to '/*.mat. or you can't convert image in colab)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "stRGWWbv6IzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import stat\n",
        "import h5py\n",
        "import glob\n",
        "import shutil\n",
        "import zipfile\n",
        "import requests\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from tqdm import notebook\n",
        "import matplotlib.image as mpimg\n",
        "from os.path import dirname as up\n",
        "\n",
        "class ImageDataExtractor():\n",
        "    \n",
        "    \"\"\"\n",
        "    A utility class to download, organize and read the *.mat files that are saved in the matlab format, \n",
        "    extract the image data that is stored as part of the file.\n",
        "    The image and the corresponding tumor mask are stored as part of the fields \n",
        "    cjdata.image & cjdata.tumorMask.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, RemoveTemporaryFiles = True):\n",
        "        \n",
        "        \"\"\"\n",
        "        A utility class to download, organize and read the *.mat files that are saved in the matlab format, \n",
        "        extract the image data that is stored as part of the file.\n",
        "        The image and the corresponding tumor mask are stored as part of the fields \n",
        "        cjdata.image & cjdata.tumorMask.\n",
        "        \n",
        "        Args:\n",
        "            RemoveTemporaryFiles (boolean): A flag to check if the downloaded files have \n",
        "                                            to be retained or deleted after the image and masks\n",
        "                                            have been extracted. Default Value - True (delete the\n",
        "                                            temp files)\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        self.__DATA = '/content/drive/MyDrive/UNet-Plus-Plus/data'\n",
        "        self.__MAT_DATA_PATH = os.path.join(self.__DATA, 'matData')\n",
        "        self.__IMG_DATA_PATH = os.path.join(self.__DATA, 'imgData', 'img')\n",
        "        self.__MASK_DATA_PATH = os.path.join(self.__DATA, 'imgData', 'mask')\n",
        "        self.__TEMP_DOWNLOAD_PATH = os.path.join(self.__DATA, 'temp', 'download')\n",
        "        self.__ZIP_FILE = os.path.join(self.__TEMP_DOWNLOAD_PATH, '1512427.zip')\n",
        "        self.__TEMP_ZIP_FILE = os.path.join(os.path.split(self.__ZIP_FILE)[0], \n",
        "                                            os.path.splitext(os.path.basename(self.__ZIP_FILE))[0] + '__.zip')\n",
        "        self.__TEMP_UNZIP_PATH = os.path.join(up(self.__TEMP_DOWNLOAD_PATH), 'unzip')\n",
        "        self.__DATA_URL = 'https://ndownloader.figshare.com/articles/1512427/versions/5'\n",
        "        self.__DATA_README_PATH = os.path.join(self.__DATA, 'README.txt')\n",
        "        self.__REMOVE_TEMP_FILES = RemoveTemporaryFiles\n",
        "        \n",
        "        # if the master 'data' folder is not present\n",
        "        # create the directory and proceed.\n",
        "        if not (os.path.isdir(self.__DATA)):\n",
        "            self.__create_dir(self.__DATA)\n",
        "        \n",
        "        # if the temp download folder is not present, create it\n",
        "        if not (os.path.isdir(self.__TEMP_DOWNLOAD_PATH)):\n",
        "            self.__create_dir(self.__TEMP_DOWNLOAD_PATH)\n",
        "        \n",
        "        # if the temp data unzip folder is not present, create it\n",
        "        if not (os.path.isdir(self.__TEMP_UNZIP_PATH)):\n",
        "            self.__create_dir(self.__TEMP_UNZIP_PATH)\n",
        "        \n",
        "    \n",
        "    def __readMatData(self, filePath: str):\n",
        "    \n",
        "        \"\"\" \n",
        "        Reads the mat file and returns the image & mask array.\n",
        "\n",
        "        Args:\n",
        "            filePath(str): Path of the file to be read.\n",
        "\n",
        "        Returns:\n",
        "            data(dict): The array of the image and the corresponding mask \n",
        "                        in the dictionary format.\n",
        "                        'image': The numpy array for image.\n",
        "                        'mask' : The numpy array for the corresponding mask.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        file = h5py.File(filePath, 'r')\n",
        "\n",
        "        imgData = dict()\n",
        "        \n",
        "        # the image and the corresponding mask are stored as part of the fields - \n",
        "        # cjdata.image & cjdata.tumorMask\n",
        "        imgData['image'] = np.array(file.get('cjdata/image'))\n",
        "        imgData['mask'] = np.array(file.get('cjdata/tumorMask'))\n",
        "\n",
        "        return imgData\n",
        "\n",
        "    def __create_dir(self, target_dir):\n",
        "\n",
        "        \"\"\"\n",
        "        Creates folder if there is no folder in the \n",
        "        specified directory path.\n",
        "\n",
        "        Args: \n",
        "            target_folder(str): path of the folder which needs to be created.\n",
        "\n",
        "        Returns: \n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        # create the directory/folder if it is not already \n",
        "        # present in the specified path.\n",
        "        if not (os.path.isdir(target_dir)):\n",
        "            os.makedirs(target_dir, exist_ok = True)\n",
        "\n",
        "    def __save_image_data(self, filename, data, imgFormat = 'png'):\n",
        "\n",
        "        \"\"\" \n",
        "        Saves the image & mask array in png format.\n",
        "\n",
        "        Args:\n",
        "            filename(str): Name of the file without the extension.\n",
        "            data(dict): The array of the image and the corresponding mask \n",
        "                        in the dictionary format.\n",
        "                        'image': The numpy array for image.\n",
        "                        'mask' : The numpy array for the corresponding mask.\n",
        "\n",
        "        Returns: \n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        img_path = os.path.join(self.__IMG_DATA_PATH, filename + '.' + imgFormat)\n",
        "        mask_path = os.path.join(self.__MASK_DATA_PATH, filename + '.' + imgFormat)\n",
        "        \n",
        "        mpimg.imsave(img_path, data['image'], cmap = 'gray', format = imgFormat)\n",
        "        mpimg.imsave(mask_path, data['mask'], cmap = 'gray', format = imgFormat)\n",
        "        \n",
        "    def downloadAndExtractImages(self):\n",
        "        \n",
        "        \"\"\" \n",
        "        Extracts the image data from the corresponding .mat files and\n",
        "        saves the extracted image & mask array in png format.\n",
        "\n",
        "        Args:\n",
        "            None\n",
        "\n",
        "        Returns: \n",
        "            None\n",
        "\n",
        "        \"\"\" \n",
        "        \n",
        "        # check if the data is already extracted. check the relevant directories are created or not.\n",
        "        if os.path.isdir(self.__MAT_DATA_PATH) and os.path.isdir(self.__IMG_DATA_PATH) and os.path.isdir(self.__MASK_DATA_PATH):\n",
        "            print(\">>> Data already downloaded. Check the following directoies\")\n",
        "            print(\"-----------------------------------------------------------\")\n",
        "            print(\">>> Mat files located @ \" + \"'\" + self.__MAT_DATA_PATH + \"'\")\n",
        "            print(\">>> Image files located @ \" + \"'\" + self.__IMG_DATA_PATH + \"'\")\n",
        "            print(\">>> Mask files located @ \" + \"'\" + self.__MASK_DATA_PATH + \"'\")\n",
        "            print(\">>> Data ReadMe located @ \" + \"'\" + self.__DATA_README_PATH + \"'\")\n",
        "            #return self.__MAT_DATA_PATH, self.__IMG_DATA_PATH, self.__MASK_DATA_PATH, self.__DATA_README_PATH\n",
        "        \n",
        "        # download & unzip the data if not present.\n",
        "        \"\"\"\n",
        "        if not (os.path.isdir(self.__MAT_DATA_PATH)):\n",
        "            self.__downloadData()\n",
        "            #!!!!!!\n",
        "            self.__upzipData()\n",
        "          \"\"\"\n",
        "        # extract the image amd the corresponding mask data.\n",
        "        #if (os.path.isdir(self.__IMG_DATA_PATH) and os.path.isdir(self.__MASK_DATA_PATH)):\n",
        "            # create the directory/folder if it is not already \n",
        "            # present in the specified path.\n",
        "        \"\"\"\n",
        "        self.__create_dir(self.__IMG_DATA_PATH)\n",
        "        self.__create_dir(self.__MASK_DATA_PATH)\n",
        "        \"\"\"\n",
        "            # extract the .mat files into a list.\n",
        "        files = glob.glob(self.__MAT_DATA_PATH + '/*.mat')\n",
        "\n",
        "        print(\">>> Extracting images and masks...\")\n",
        "\n",
        "        for idx in  notebook.tqdm(range(len(files))):\n",
        "          file = files[idx]\n",
        "\n",
        "                # extract the filename to be used to save the \n",
        "                # image and its mask.\n",
        "          filename = os.path.splitext(os.path.basename(file))[0]\n",
        "\n",
        "          data = self.__readMatData(file)\n",
        "          self.__save_image_data(filename, data)\n",
        "        print(\">>> Data extraction complete...\")\n",
        "        \n",
        "        # remove the files only if the flag is set\n",
        "        if self.__REMOVE_TEMP_FILES:\n",
        "            print(\">>> Removing the master zip file...\")\n",
        "            if os.path.isfile(self.__ZIP_FILE):\n",
        "                os.remove(self.__ZIP_FILE)\n",
        "\n",
        "            # delete the temp folder @ temp_unzip_path\n",
        "            if (os.path.isdir(self.__TEMP_UNZIP_PATH)):\n",
        "                print(\">>> Removing the temp folder created for download...\" + \"'\" + self.__TEMP_DOWNLOAD_PATH + \"'\")\n",
        "                shutil.rmtree(up(self.__TEMP_DOWNLOAD_PATH))\n",
        "        \n",
        "        print(\"\\n>>> Data loaded into the following directoies\")\n",
        "        print(\"-----------------------------------------------\")\n",
        "        print(\">>> Mat files located @ \" + \"'\" + self.__MAT_DATA_PATH + \"'\")\n",
        "        print(\">>> Image files located @ \" + \"'\" + self.__IMG_DATA_PATH + \"'\")\n",
        "        print(\">>> Mask files located @ \" + \"'\" + self.__MASK_DATA_PATH + \"'\")\n",
        "        print(\">>> Data ReadMe located @ \" + \"'\" + self.__DATA_README_PATH + \"'\")\n",
        "           \n",
        "        # return the data directories path to the caller.\n",
        "        return self.__MAT_DATA_PATH, self.__IMG_DATA_PATH, self.__MASK_DATA_PATH, self.__DATA_README_PATH\n",
        "         \n",
        "    def __downloadData(self, chunk_size = 1024):\n",
        "    \n",
        "        \"\"\" \n",
        "        Download the file from the given url.\n",
        "\n",
        "        Args:\n",
        "            chunk_size (int):  number of bytes it should read into memory. Default Value is 1024\n",
        "\n",
        "        Returns: \n",
        "            None\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # Delete the incomplete downloads from previous sessions.\n",
        "        if os.path.isfile(self.__TEMP_ZIP_FILE):\n",
        "            print('>>> Deleting any incomplete downloaded file from previous session @ ' + self.__TEMP_ZIP_FILE)\n",
        "            os.remove(self.__TEMP_ZIP_FILE)\n",
        "\n",
        "        # Download the file\n",
        "        print(\">>> Downloading data to - \" + \"'\" + self.__TEMP_ZIP_FILE + \"'\")\n",
        "        response = requests.get(self.__DATA_URL, stream = True)\n",
        "        with open(self.__TEMP_ZIP_FILE, \"wb\") as handle:\n",
        "\n",
        "            total_size = round(int(response.headers['Content-Length']), 3)\n",
        "            pbar = notebook.tqdm(unit = \"B\", total = total_size)\n",
        "            for chunk in response.iter_content(chunk_size = chunk_size):\n",
        "                if chunk:  # filter out keep-alive new chunks\n",
        "                    handle.write(chunk)\n",
        "                    pbar.update(len(chunk))\n",
        "\n",
        "        # Rename the file to the correct name \n",
        "        # once download is complete.\n",
        "        os.rename(self.__TEMP_ZIP_FILE, self.__ZIP_FILE)\n",
        "        print(\">>> Download Complete...\")\n",
        "        \n",
        "    def __upzipData(self):\n",
        "        \n",
        "        \"\"\"\n",
        "        extracts the downloaded data, data readme file\n",
        "        and prepares to read the images and masks.\n",
        "        \n",
        "        Args:\n",
        "            None\n",
        "        \n",
        "        Return:\n",
        "            None\n",
        "        \n",
        "        \"\"\"\n",
        "    \n",
        "        self.__create_dir(self.__TEMP_UNZIP_PATH)\n",
        "\n",
        "        # extract the master zipped file.\n",
        "        print(\">>> Extracting Master Folder...\")\n",
        "        for idx in  notebook.tqdm(range(1)):\n",
        "            with zipfile.ZipFile(self.__ZIP_FILE, \"r\") as _zip:\n",
        "                _zip.extractall(self.__TEMP_UNZIP_PATH)\n",
        "\n",
        "        print(\">>> Extracting *.mat files...\")\n",
        "        files = glob.glob(self.__TEMP_UNZIP_PATH + '\\*.zip')\n",
        "\n",
        "        self.__create_dir(self.__MAT_DATA_PATH)\n",
        "\n",
        "        # exract the mat files from the respective zipped files.\n",
        "        for idx in  notebook.tqdm(range(len(files))):\n",
        "                with zipfile.ZipFile(files[idx], \"r\") as _zip:\n",
        "                    _zip.extractall(self.__MAT_DATA_PATH)\n",
        "        \n",
        "        # copy the data readme file to the data folder.\n",
        "        readMeDestination = self.__DATA\n",
        "        readMeFileName = os.path.split('data\\\\temp\\\\unzip\\\\README.txt')[1]\n",
        "        \n",
        "        # set the data readme path to return to the caller.\n",
        "        self.__DATA_README_PATH = os.path.join(readMeDestination, readMeFileName)\n",
        "        print(\">>> Copying the data ReadMe file to - \" + \"'\\\\\" + self.__DATA_README_PATH + \"'\")\n",
        "        readMe = glob.glob(self.__TEMP_UNZIP_PATH + '\\*.txt')\n",
        "        \n",
        "        # copy the readme file to the data folder.\n",
        "        #shutil.copy2(readMe[0], readMeDestination)\n",
        "        \n",
        "        print(\">>> Data unzipped successfully to \" + \"'\" + self.__MAT_DATA_PATH + \"'\")\n"
      ],
      "metadata": {
        "id": "n-iIhi4H6JLe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip '/content/Untitled Folder/1512427.zip'"
      ],
      "metadata": {
        "id": "htrc5uE1WZx9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 变量设置"
      ],
      "metadata": {
        "id": "z7OyXYT-1Rdm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 128\n",
        "image_channels = 1\n",
        "epochs = 30\n",
        "batch_size = 64\n",
        "\n",
        "# there are a total of 3064 images.\n",
        "# so fixing 2900 of data available for training set\n",
        "# 200 for validation set and 64 for test set.\n",
        "validation_data_size = 200\n",
        "test_data_size = 64\n",
        "train_data_size = 2800\n",
        "train_steps = 10\n",
        "valid_steps = 2\n",
        "MAT_DATA_PATH = '/content/drive/MyDrive/UNet-Plus-Plus/data/matData'\n",
        "IMG_DATA_PATH = '/content/drive/MyDrive/UNet-Plus-Plus/data/imgData/img'\n",
        "MASK_DATA_PATH = '/content/drive/MyDrive/UNet-Plus-Plus/data/imgData/mask'"
      ],
      "metadata": {
        "id": "S0S031Fw-eS_"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 第一次跑"
      ],
      "metadata": {
        "id": "IOoM4Hxy1KxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataExtractor = ImageDataExtractor(RemoveTemporaryFiles = True)\n",
        "MAT_DATA_PATH, IMG_DATA_PATH, MASK_DATA_PATH, DATA_README_PATH = dataExtractor.downloadAndExtractImages()"
      ],
      "metadata": {
        "id": "z-rzdweM6Ud_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAT_DATA_PATH, IMG_DATA_PATH, MASK_DATA_PATH, DATA_README_PATH"
      ],
      "metadata": {
        "id": "LXzbY1DO6Z2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/data/temp/download/1512427.zip"
      ],
      "metadata": {
        "id": "kS-KJQhtlHaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/brainTumorDataPublic_1-766.zip -d /content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/data/temp/unzip"
      ],
      "metadata": {
        "id": "ONTrZlbXlg_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/brainTumorDataPublic_2299-3064.zip -d /content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/data/temp/unzip\n",
        "!unzip /content/brainTumorDataPublic_767-1532.zip -d /content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/data/temp/unzip\n",
        "!unzip /content/brainTumorDataPublic_1533-2298.zip -d /content/drive/MyDrive/UNet-Plus-Plus---Brain-Tumor-Segmentation/data/temp/unzip"
      ],
      "metadata": {
        "id": "V2IBGn83nSPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VisualizeImageAndMask"
      ],
      "metadata": {
        "id": "LeXxiAPrBBfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def VisualizeImageAndMask(image, mask, prediction_img = None):\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    Displays the image, mask and the predicted mask\n",
        "    of the input image.\n",
        "    \n",
        "    Args:\n",
        "        image: the original image.\n",
        "        mask: the given mask of the image.\n",
        "        prediction_img: the predicted mask of the image.\n",
        "        \n",
        "    Return:\n",
        "        None\n",
        "        \n",
        "    \"\"\"\n",
        "    fig = plt.figure()\n",
        "    fig.subplots_adjust(hspace = 0.6, wspace = 0.6)\n",
        "    fig.suptitle('Image & Mask(s)', fontsize = 15)\n",
        "    fig.subplots_adjust(top = 1.15)\n",
        "    \n",
        "    ax = fig.add_subplot(1, 3, 1)\n",
        "    ax.imshow(image, cmap = \"gray\")\n",
        "    setTitleAndRemoveTicks(ax, 'Original\\nImage')\n",
        "    \n",
        "    ax = fig.add_subplot(1, 3, 2)\n",
        "    ax.imshow(mask, cmap = \"gray\")\n",
        "    setTitleAndRemoveTicks(ax, 'Original\\nMask')\n",
        "    \n",
        "    if prediction_img is not None:\n",
        "        #prediction_img = prediction_img * 255\n",
        "        ax = fig.add_subplot(1, 3, 3)\n",
        "        ax.imshow(np.reshape(prediction_img, (image_size, image_size)), cmap = \"gray\")\n",
        "        setTitleAndRemoveTicks(ax, 'Predicted\\nMask')\n",
        "    \n",
        "def setTitleAndRemoveTicks(axes, title):\n",
        "    \n",
        "    \"\"\"\n",
        "    Sets the sub-plot title and removes the \n",
        "    x & y ticks on the respective axes.\n",
        "    \n",
        "    Args:\n",
        "        axes: the subplot.\n",
        "        title: title of the subplot.\n",
        "        \n",
        "    Return:\n",
        "        None\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    # set plot title\n",
        "    axes.title.set_text(title)\n",
        "    \n",
        "    # remove the ticks\n",
        "    axes.set_xticks([])\n",
        "    axes.set_yticks([])"
      ],
      "metadata": {
        "id": "iXofhJlj-hEf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### environment test"
      ],
      "metadata": {
        "id": "0BZY-eOUBiqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the ids of the images.\n",
        "# os.walk yields a 3-tuple (dirpath, dirnames, filenames). We need the directory names here.\n",
        "# IMG_DATA_PATH = 'data\\\\imgData\\\\img'\n",
        "# MASK_DATA_PATH = 'data\\\\imgData\\\\mask'\n",
        "image_ids = next(os.walk(IMG_DATA_PATH))[2]\n",
        "np.random.shuffle(image_ids)\n",
        "\n",
        "# partition the data into train, test and validation sets.\n",
        "testing_data_ids = image_ids[:test_data_size]\n",
        "validation_data_ids = image_ids[:validation_data_size]\n",
        "training_data_ids = image_ids[:train_data_size]"
      ],
      "metadata": {
        "id": "1prdgxgJ-rIM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_data_generator = ImageDataGen(image_ids = training_data_ids,\n",
        "                                   img_path = IMG_DATA_PATH, \n",
        "                                   mask_path = MASK_DATA_PATH,\n",
        "                                   batch_size = batch_size, \n",
        "                                   image_size = image_size)\n",
        "\n",
        "# get one batch of data\n",
        "images, masks = temp_data_generator.__getitem__(0)\n",
        "print(\"Batch Dimension Details:\", images.shape, masks.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of_66PWq-u5B",
        "outputId": "49d7f03c-dcd3-428f-b7b3-3b618924cfd5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Dimension Details: (64, 128, 128) (64, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VisualizeImageAndMask(image = images[1], mask = masks[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "1O1V8vh4_EAq",
        "outputId": "0c78d197-88da-4be8-a934-347af9f0c5d5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_data_generator = None"
      ],
      "metadata": {
        "id": "MvbAt439xhZ-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Unet++ with the default parameters. \n",
        "# The default params are the one that were used in the original paper.\n",
        "# Input shape - (512, 512, 1), \n",
        "# filters [32, 64, 128, 256, 512].\n",
        "UNetPP = UNetPlusPlus(input_shape = (128, 128, 1), deep_supervision = False)\n",
        "\n",
        "# call the build netowrk API to build the network.\n",
        "model = UNetPP.BuildNetwork()"
      ],
      "metadata": {
        "id": "lS1IEME5xjgQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile & summarize the model\n",
        "if model is not None:\n",
        "    UNetPP.CompileAndSummarizeModel(model = model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEUUGd8KxkkR",
        "outputId": "27646ce3-251b-49fe-9207-19fbba8f89be"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"UNetPP\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " InputLayer (InputLayer)        [(None, 128, 128, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv00_1 (Conv2D)              (None, 128, 128, 32  320         ['InputLayer[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X00_ (Dropout)                 (None, 128, 128, 32  0           ['conv00_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv00_2 (Conv2D)              (None, 128, 128, 32  9248        ['X00_[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X00 (Dropout)                  (None, 128, 128, 32  0           ['conv00_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool0 (MaxPooling2D)           (None, 64, 64, 32)   0           ['X00[0][0]']                    \n",
            "                                                                                                  \n",
            " conv10_1 (Conv2D)              (None, 64, 64, 64)   18496       ['pool0[0][0]']                  \n",
            "                                                                                                  \n",
            " X10_ (Dropout)                 (None, 64, 64, 64)   0           ['conv10_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv10_2 (Conv2D)              (None, 64, 64, 64)   36928       ['X10_[0][0]']                   \n",
            "                                                                                                  \n",
            " X10 (Dropout)                  (None, 64, 64, 64)   0           ['conv10_2[0][0]']               \n",
            "                                                                                                  \n",
            " pool1 (MaxPooling2D)           (None, 32, 32, 64)   0           ['X10[0][0]']                    \n",
            "                                                                                                  \n",
            " conv20_1 (Conv2D)              (None, 32, 32, 128)  73856       ['pool1[0][0]']                  \n",
            "                                                                                                  \n",
            " X20_ (Dropout)                 (None, 32, 32, 128)  0           ['conv20_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv20_2 (Conv2D)              (None, 32, 32, 128)  147584      ['X20_[0][0]']                   \n",
            "                                                                                                  \n",
            " X20 (Dropout)                  (None, 32, 32, 128)  0           ['conv20_2[0][0]']               \n",
            "                                                                                                  \n",
            " pool2 (MaxPooling2D)           (None, 16, 16, 128)  0           ['X20[0][0]']                    \n",
            "                                                                                                  \n",
            " conv30_1 (Conv2D)              (None, 16, 16, 256)  295168      ['pool2[0][0]']                  \n",
            "                                                                                                  \n",
            " X30_ (Dropout)                 (None, 16, 16, 256)  0           ['conv30_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv30_2 (Conv2D)              (None, 16, 16, 256)  590080      ['X30_[0][0]']                   \n",
            "                                                                                                  \n",
            " X30 (Dropout)                  (None, 16, 16, 256)  0           ['conv30_2[0][0]']               \n",
            "                                                                                                  \n",
            " pool3 (MaxPooling2D)           (None, 8, 8, 256)    0           ['X30[0][0]']                    \n",
            "                                                                                                  \n",
            " conv40_1 (Conv2D)              (None, 8, 8, 512)    1180160     ['pool3[0][0]']                  \n",
            "                                                                                                  \n",
            " X40_ (Dropout)                 (None, 8, 8, 512)    0           ['conv40_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv40_2 (Conv2D)              (None, 8, 8, 512)    2359808     ['X40_[0][0]']                   \n",
            "                                                                                                  \n",
            " X40 (Dropout)                  (None, 8, 8, 512)    0           ['conv40_2[0][0]']               \n",
            "                                                                                                  \n",
            " upsample31 (Conv2DTranspose)   (None, 16, 16, 256)  524544      ['X40[0][0]']                    \n",
            "                                                                                                  \n",
            " concat31 (Concatenate)         (None, 16, 16, 512)  0           ['upsample31[0][0]',             \n",
            "                                                                  'X30[0][0]']                    \n",
            "                                                                                                  \n",
            " upsample21 (Conv2DTranspose)   (None, 32, 32, 128)  131200      ['X30[0][0]']                    \n",
            "                                                                                                  \n",
            " conv31_1 (Conv2D)              (None, 16, 16, 256)  1179904     ['concat31[0][0]']               \n",
            "                                                                                                  \n",
            " concat21 (Concatenate)         (None, 32, 32, 256)  0           ['upsample21[0][0]',             \n",
            "                                                                  'X20[0][0]']                    \n",
            "                                                                                                  \n",
            " upsample11 (Conv2DTranspose)   (None, 64, 64, 64)   32832       ['X20[0][0]']                    \n",
            "                                                                                                  \n",
            " X31_ (Dropout)                 (None, 16, 16, 256)  0           ['conv31_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv21_1 (Conv2D)              (None, 32, 32, 128)  295040      ['concat21[0][0]']               \n",
            "                                                                                                  \n",
            " concat11 (Concatenate)         (None, 64, 64, 128)  0           ['upsample11[0][0]',             \n",
            "                                                                  'X10[0][0]']                    \n",
            "                                                                                                  \n",
            " upsample01 (Conv2DTranspose)   (None, 128, 128, 32  8224        ['X10[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv31_2 (Conv2D)              (None, 16, 16, 256)  590080      ['X31_[0][0]']                   \n",
            "                                                                                                  \n",
            " X21_ (Dropout)                 (None, 32, 32, 128)  0           ['conv21_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv11_1 (Conv2D)              (None, 64, 64, 64)   73792       ['concat11[0][0]']               \n",
            "                                                                                                  \n",
            " concat01 (Concatenate)         (None, 128, 128, 64  0           ['upsample01[0][0]',             \n",
            "                                )                                 'X00[0][0]']                    \n",
            "                                                                                                  \n",
            " X31 (Dropout)                  (None, 16, 16, 256)  0           ['conv31_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv21_2 (Conv2D)              (None, 32, 32, 128)  147584      ['X21_[0][0]']                   \n",
            "                                                                                                  \n",
            " X11_ (Dropout)                 (None, 64, 64, 64)   0           ['conv11_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv01_1 (Conv2D)              (None, 128, 128, 32  18464       ['concat01[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " upsample22 (Conv2DTranspose)   (None, 32, 32, 128)  131200      ['X31[0][0]']                    \n",
            "                                                                                                  \n",
            " X21 (Dropout)                  (None, 32, 32, 128)  0           ['conv21_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv11_2 (Conv2D)              (None, 64, 64, 64)   36928       ['X11_[0][0]']                   \n",
            "                                                                                                  \n",
            " X01_ (Dropout)                 (None, 128, 128, 32  0           ['conv01_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat22 (Concatenate)         (None, 32, 32, 384)  0           ['upsample22[0][0]',             \n",
            "                                                                  'X20[0][0]',                    \n",
            "                                                                  'X21[0][0]']                    \n",
            "                                                                                                  \n",
            " X11 (Dropout)                  (None, 64, 64, 64)   0           ['conv11_2[0][0]']               \n",
            "                                                                                                  \n",
            " upsample12 (Conv2DTranspose)   (None, 64, 64, 64)   32832       ['X21[0][0]']                    \n",
            "                                                                                                  \n",
            " conv01_2 (Conv2D)              (None, 128, 128, 32  9248        ['X01_[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv22_1 (Conv2D)              (None, 32, 32, 128)  442496      ['concat22[0][0]']               \n",
            "                                                                                                  \n",
            " concat12 (Concatenate)         (None, 64, 64, 192)  0           ['upsample12[0][0]',             \n",
            "                                                                  'X10[0][0]',                    \n",
            "                                                                  'X11[0][0]']                    \n",
            "                                                                                                  \n",
            " X01 (Dropout)                  (None, 128, 128, 32  0           ['conv01_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " upsample02 (Conv2DTranspose)   (None, 128, 128, 32  8224        ['X11[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X22_ (Dropout)                 (None, 32, 32, 128)  0           ['conv22_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv12_1 (Conv2D)              (None, 64, 64, 64)   110656      ['concat12[0][0]']               \n",
            "                                                                                                  \n",
            " concat02 (Concatenate)         (None, 128, 128, 96  0           ['upsample02[0][0]',             \n",
            "                                )                                 'X00[0][0]',                    \n",
            "                                                                  'X01[0][0]']                    \n",
            "                                                                                                  \n",
            " conv22_2 (Conv2D)              (None, 32, 32, 128)  147584      ['X22_[0][0]']                   \n",
            "                                                                                                  \n",
            " X12_ (Dropout)                 (None, 64, 64, 64)   0           ['conv12_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv02_1 (Conv2D)              (None, 128, 128, 32  27680       ['concat02[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X22 (Dropout)                  (None, 32, 32, 128)  0           ['conv22_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv12_2 (Conv2D)              (None, 64, 64, 64)   36928       ['X12_[0][0]']                   \n",
            "                                                                                                  \n",
            " X02_ (Dropout)                 (None, 128, 128, 32  0           ['conv02_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " upsample13 (Conv2DTranspose)   (None, 64, 64, 64)   32832       ['X22[0][0]']                    \n",
            "                                                                                                  \n",
            " X12 (Dropout)                  (None, 64, 64, 64)   0           ['conv12_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv02_2 (Conv2D)              (None, 128, 128, 32  9248        ['X02_[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat13 (Concatenate)         (None, 64, 64, 256)  0           ['upsample13[0][0]',             \n",
            "                                                                  'X10[0][0]',                    \n",
            "                                                                  'X11[0][0]',                    \n",
            "                                                                  'X12[0][0]']                    \n",
            "                                                                                                  \n",
            " X02 (Dropout)                  (None, 128, 128, 32  0           ['conv02_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " upsample03 (Conv2DTranspose)   (None, 128, 128, 32  8224        ['X12[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv13_1 (Conv2D)              (None, 64, 64, 64)   147520      ['concat13[0][0]']               \n",
            "                                                                                                  \n",
            " concat03 (Concatenate)         (None, 128, 128, 12  0           ['upsample03[0][0]',             \n",
            "                                8)                                'X00[0][0]',                    \n",
            "                                                                  'X01[0][0]',                    \n",
            "                                                                  'X02[0][0]']                    \n",
            "                                                                                                  \n",
            " X13_ (Dropout)                 (None, 64, 64, 64)   0           ['conv13_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv03_1 (Conv2D)              (None, 128, 128, 32  36896       ['concat03[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv13_2 (Conv2D)              (None, 64, 64, 64)   36928       ['X13_[0][0]']                   \n",
            "                                                                                                  \n",
            " X03_ (Dropout)                 (None, 128, 128, 32  0           ['conv03_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X13 (Dropout)                  (None, 64, 64, 64)   0           ['conv13_2[0][0]']               \n",
            "                                                                                                  \n",
            " conv03_2 (Conv2D)              (None, 128, 128, 32  9248        ['X03_[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " upsample04 (Conv2DTranspose)   (None, 128, 128, 32  8224        ['X13[0][0]']                    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X03 (Dropout)                  (None, 128, 128, 32  0           ['conv03_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat04 (Concatenate)         (None, 128, 128, 16  0           ['upsample04[0][0]',             \n",
            "                                0)                                'X00[0][0]',                    \n",
            "                                                                  'X01[0][0]',                    \n",
            "                                                                  'X02[0][0]',                    \n",
            "                                                                  'X03[0][0]']                    \n",
            "                                                                                                  \n",
            " conv04_1 (Conv2D)              (None, 128, 128, 32  46112       ['concat04[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X04_ (Dropout)                 (None, 128, 128, 32  0           ['conv04_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv04_2 (Conv2D)              (None, 128, 128, 32  9248        ['X04_[0][0]']                   \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " X04 (Dropout)                  (None, 128, 128, 32  0           ['conv04_2[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " op4 (Conv2D)                   (None, 128, 128, 1)  33          ['X04[0][0]']                    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 9,041,601\n",
            "Trainable params: 9,041,601\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train"
      ],
      "metadata": {
        "id": "AbCfnhbz1YyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_gen = ImageDataGen(image_ids = training_data_ids,\n",
        "                         img_path = IMG_DATA_PATH, \n",
        "                         mask_path = MASK_DATA_PATH, \n",
        "                         image_size = image_size, \n",
        "                         batch_size = batch_size)\n",
        "\n",
        "valid_gen = ImageDataGen(image_ids = validation_data_ids, \n",
        "                         img_path = IMG_DATA_PATH, \n",
        "                         mask_path = MASK_DATA_PATH,\n",
        "                         image_size = image_size, \n",
        "                         batch_size = batch_size)\n",
        "\n",
        "test_gen = ImageDataGen(image_ids = testing_data_ids, \n",
        "                        img_path = IMG_DATA_PATH, \n",
        "                        mask_path = MASK_DATA_PATH,\n",
        "                        image_size = image_size, \n",
        "                        batch_size = batch_size)\n",
        "\n",
        "#train_steps = len(training_data_ids)//batch_size\n",
        "#valid_steps = len(validation_data_ids)//batch_size\n",
        "train_steps = 10\n",
        "valid_steps = 2"
      ],
      "metadata": {
        "id": "6Q0QIeghyqmb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps, valid_steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loRBWQgRz0EK",
        "outputId": "449bbec5-a87e-498a-94c9-8389d72c2923"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_gen, \n",
        "          validation_data = valid_gen, \n",
        "          steps_per_epoch = train_steps, \n",
        "          validation_steps = valid_steps, \n",
        "          epochs = 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgZ16facz2FT",
        "outputId": "a59302be-2591-4c6c-b886-0423516b4040"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 75s 8s/step - loss: 0.7961 - acc: 0.9795 - __iou_loss_core: 0.4465 - val_loss: 0.8258 - val_acc: 0.9484 - val___iou_loss_core: 0.3549\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 53s 5s/step - loss: 0.7843 - acc: 0.9813 - __iou_loss_core: 0.4600 - val_loss: 0.7579 - val_acc: 0.9809 - val___iou_loss_core: 0.3907\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 43s 4s/step - loss: 0.7532 - acc: 0.9798 - __iou_loss_core: 0.4880 - val_loss: 0.7392 - val_acc: 0.9809 - val___iou_loss_core: 0.4904\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 33s 3s/step - loss: 0.6987 - acc: 0.9693 - __iou_loss_core: 0.5279 - val_loss: 0.9957 - val_acc: 0.9818 - val___iou_loss_core: 0.8539\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 32s 3s/step - loss: 0.6524 - acc: 0.9777 - __iou_loss_core: 0.5879 - val_loss: 0.9987 - val_acc: 0.9812 - val___iou_loss_core: 0.8582\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 28s 3s/step - loss: 0.6580 - acc: 0.9794 - __iou_loss_core: 0.6105 - val_loss: 0.9301 - val_acc: 0.9803 - val___iou_loss_core: 0.7661\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 28s 3s/step - loss: 0.6223 - acc: 0.9802 - __iou_loss_core: 0.6354 - val_loss: 0.9798 - val_acc: 0.9805 - val___iou_loss_core: 0.8230\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 32s 3s/step - loss: 0.6301 - acc: 0.9817 - __iou_loss_core: 0.6326 - val_loss: 0.9985 - val_acc: 0.9806 - val___iou_loss_core: 0.8503\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.6227 - acc: 0.9782 - __iou_loss_core: 0.6077 - val_loss: 0.9226 - val_acc: 0.9814 - val___iou_loss_core: 0.7951\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 20s 2s/step - loss: 0.5930 - acc: 0.9797 - __iou_loss_core: 0.6301 - val_loss: 0.9060 - val_acc: 0.9822 - val___iou_loss_core: 0.8197\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 7s 744ms/step - loss: 0.6182 - acc: 0.9783 - __iou_loss_core: 0.5944 - val_loss: 0.9525 - val_acc: 0.9805 - val___iou_loss_core: 0.7749\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 7s 733ms/step - loss: 0.6398 - acc: 0.9794 - __iou_loss_core: 0.5660 - val_loss: 0.8133 - val_acc: 0.9822 - val___iou_loss_core: 0.7775\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 8s 798ms/step - loss: 0.6214 - acc: 0.9782 - __iou_loss_core: 0.6227 - val_loss: 0.9991 - val_acc: 0.9816 - val___iou_loss_core: 0.8576\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 7s 729ms/step - loss: 0.5960 - acc: 0.9801 - __iou_loss_core: 0.5947 - val_loss: 0.9353 - val_acc: 0.9800 - val___iou_loss_core: 0.8237\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 8s 802ms/step - loss: 0.5702 - acc: 0.9817 - __iou_loss_core: 0.6278 - val_loss: 0.9727 - val_acc: 0.9813 - val___iou_loss_core: 0.8334\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f12863c8d50>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test"
      ],
      "metadata": {
        "id": "lcSDZhKN4yNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = \"models\"\n",
        "model_name = \"UNetpp_BrainTumorSegment.h5\"\n",
        "\n",
        "if not os.path.isdir(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "model.save_weights(os.path.join(model_dir, model_name))"
      ],
      "metadata": {
        "id": "yxO21Q-a4mTG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = ImageDataGen(image_ids = testing_data_ids, \n",
        "                        img_path = IMG_DATA_PATH, \n",
        "                        mask_path = MASK_DATA_PATH,\n",
        "                        image_size = image_size, \n",
        "                        batch_size = 32)"
      ],
      "metadata": {
        "id": "RoyAd-E04o5s"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images, test_masks = test_gen.__getitem__(0)\n",
        "predicted_masks = model.predict(test_images)\n",
        "\n",
        "predicted_masks = predicted_masks"
      ],
      "metadata": {
        "id": "J49DVEcy4qFW"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_2, test_masks_2 = test_gen.__getitem__(1)\n",
        "predicted_masks_2 = model.predict(test_images)\n",
        "\n",
        "predicted_masks_ = predicted_masks"
      ],
      "metadata": {
        "id": "u7aMWVpJ8ELv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VisualizeImageAndMask(image = test_images_2[4], mask = test_masks_2[4], prediction_img = predicted_masks_[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "KsHocmFG4wN9",
        "outputId": "c77d7945-02b3-4f25-eb28-9efbee77ebfb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}